{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "985ba55d-7193-4b6f-85b9-51ed35d27552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of the experiments in the paper SPLADE v2: Sparse Lexical and\n",
    "# Expansion Model for Information Retrieval, (Thibault Formal, Carlos Lassance,\n",
    "# Benjamin Piwowarski, Stéphane Clinchant), 2021\n",
    "# https://arxiv.org/abs/2109.10086\n",
    "\n",
    "import logging\n",
    "from functools import lru_cache\n",
    "\n",
    "from experimaestro.launcherfinder import find_launcher\n",
    "\n",
    "from experimaestro import tag, setmeta, experiment\n",
    "from xpmir.distributed import DistributedHook\n",
    "from xpmir.letor.learner import Learner, ValidationListener\n",
    "from xpmir.letor.schedulers import LinearWithWarmup\n",
    "from xpmir.index.sparse import (\n",
    "    SparseRetriever,\n",
    "    SparseRetrieverIndexBuilder,\n",
    ")\n",
    "from xpmir.letor.distillation.pairwise import (\n",
    "    DistillationPairwiseTrainer,\n",
    "    MSEDifferenceLoss,\n",
    ")\n",
    "#from xpmir.papers.cli import paper_command\n",
    "from xpmir.letor.samplers import PairwiseSampler\n",
    "from xpmir.letor.trainers.batchwise import BatchwiseTrainer, SoftmaxCrossEntropy\n",
    "from xpmir.letor.batchers import PowerAdaptativeBatcher\n",
    "from xpmir.neural.dual import DenseDocumentEncoder, DenseQueryEncoder\n",
    "from xpmir.letor.optim import (\n",
    "    ParameterOptimizer,\n",
    "    AdamW,\n",
    "    get_optimizers,\n",
    ")\n",
    "from xpmir.rankers.standard import BM25\n",
    "from xpmir.neural.splade import spladeV2_max, spladeV2_doc\n",
    "from xpmir.papers.results import PaperResults\n",
    "from xpmir.papers.splade.pipeline_trec import SPLADETRECCast2020Experiment\n",
    "from xpmir.papers.splade.configuration_trec import SPLADE_TREC, Learner_TREC as LearnerConfig\n",
    "from experimaestro.utils.jobs import jobmonitor\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from IPython.display import display, Markdown, Latex\n",
    "import xpmir.letor.trainers.pairwise as pairwise\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Espace pour les fichiers\n",
    "libpath = Path(\".\") / \"lib\" / \"xpmir_userlib\"\n",
    "libpath.mkdir(parents=True, exist_ok=True)\n",
    "(libpath / \"__init__.py\").touch()\n",
    "libpath = str(libpath.absolute().parent)\n",
    "if libpath not in sys.path:\n",
    "    sys.path.append(libpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cabec4f-3e98-4425-b040-712786bb3f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea7f91ede9644166aff63d843ce62d79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Start the experimaestro server', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0e1fc3f8e0c404b94ce0992b12bad15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:xpmir.letor.optim:tensorboard --logdir=/home/gameselo/Bureau/M1_DAC_2022_2023/PLDAC/xp/ri/xp/xp/ri/results/runs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server started : http://localhost:12500/auth?xpm-token=763033d7784e4c9fa7620637c8326888\n"
     ]
    }
   ],
   "source": [
    "from experimaestro.utils.jupyter import serverwidget\n",
    "from xpmir.letor.optim import TensorboardService\n",
    "\n",
    "tb = []\n",
    "def init_xp(xp):\n",
    "    # Évite que plus d'une tâche ne s'exécute à la fois|\n",
    "    # TODO: use GLOBAL token\n",
    "    xp.token = xp.current.token(\"main\", 1)\n",
    "    \n",
    "    tb.clear()\n",
    "    tb.append(xp.current.add_service(TensorboardService(xp.current.resultspath / \"runs\")))\n",
    "    xp.current.setenv(\"PYTHONPATH\", libpath)\n",
    "\n",
    "xp = serverwidget(\"xp/ri\", environment={\"JAVA_HOME\": \"/usr/lib/jvm/java-11-openjdk-amd64\"}, port=12500, hook=init_xp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c65a5563-b8e5-45ef-970e-f9a16dee0f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:xpm:Submitting job Job[19124417b1a856b73072568f25fb3a315218938e07d4b3851527cf6d7dd8eb92]\n",
      "INFO:xpm:Starting job /home/gameselo/Bureau/M1_DAC_2022_2023/PLDAC/xp/ri/jobs/xpmir.datasets.adapters.randomfold/19124417b1a856b73072568f25fb3a315218938e07d4b3851527cf6d7dd8eb92\n",
      "INFO:xpm:Process started (Process(5868))\n",
      "INFO:xpm:Submitting job Job[997eebf3cefd37ca643691f7c7c3c87d0a8e88319277b9eeed0db59ee8aae7a9]\n",
      "INFO:xpm:Starting job /home/gameselo/Bureau/M1_DAC_2022_2023/PLDAC/xp/ri/jobs/xpmir.datasets.adapters.randomfold/997eebf3cefd37ca643691f7c7c3c87d0a8e88319277b9eeed0db59ee8aae7a9\n",
      "INFO:xpm:Process started (Process(5872))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ca43ae023984bf983267ee2e6394d23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/100 [00:00<?, ?%/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:geventwebsocket.handler:127.0.0.1 - - [2023-04-09 21:16:48] \"GET /notifications/19124417b1a856b73072568f25fb3a315218938e07d4b3851527cf6d7dd8eb92/progress?level=0&progress=0 HTTP/1.1\" 200 115 0.001435\n",
      "INFO:geventwebsocket.handler:127.0.0.1 - - [2023-04-09 21:16:48] \"GET /notifications/19124417b1a856b73072568f25fb3a315218938e07d4b3851527cf6d7dd8eb92?status=eoj HTTP/1.1\" 404 137 0.000969\n",
      "INFO:geventwebsocket.handler:127.0.0.1 - - [2023-04-09 21:16:48] \"GET /notifications/997eebf3cefd37ca643691f7c7c3c87d0a8e88319277b9eeed0db59ee8aae7a9/progress?level=0&progress=0 HTTP/1.1\" 200 115 0.000477\n",
      "INFO:geventwebsocket.handler:127.0.0.1 - - [2023-04-09 21:16:48] \"GET /notifications/997eebf3cefd37ca643691f7c7c3c87d0a8e88319277b9eeed0db59ee8aae7a9?status=eoj HTTP/1.1\" 404 137 0.000573\n",
      "INFO:xpm:Processing 0 dependent jobs\n",
      "INFO:xpm:Processing 0 dependent jobs\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Job did not complete successfully (ERROR).Check the error log /home/gameselo/Bureau/M1_DAC_2022_2023/PLDAC/xp/ri/jobs/xpmir.datasets.adapters.randomfold/19124417b1a856b73072568f25fb3a315218938e07d4b3851527cf6d7dd8eb92/randomfold.err",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [3], line 147\u001b[0m\n\u001b[1;32m    142\u001b[0m         jobmonitor(sparse_index)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m#@paper_command(schema=SPLADE, package=__package__)\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m SPLADEIndex(experiment, SPLADE_TREC)\u001b[38;5;241m.\u001b[39mrun()\n",
      "Cell \u001b[0;32mIn [3], line 13\u001b[0m, in \u001b[0;36mSPLADEIndex.__init__\u001b[0;34m(self, xp, cfg)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, xp: experiment, cfg: SPLADE_TREC):\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgpu_launcher_learner \u001b[38;5;241m=\u001b[39m find_launcher(cfg\u001b[38;5;241m.\u001b[39mlearner\u001b[38;5;241m.\u001b[39mrequirements)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgpu_launcher_evaluate \u001b[38;5;241m=\u001b[39m find_launcher(cfg\u001b[38;5;241m.\u001b[39mevaluation\u001b[38;5;241m.\u001b[39mrequirements)\n",
      "File \u001b[0;32m~/Bureau/M1_DAC_2022_2023/PLDAC/experimaestro-ir/src/xpmir/papers/splade/pipeline_trec.py:102\u001b[0m, in \u001b[0;36mSPLADETRECCast2020Experiment.__init__\u001b[0;34m(self, xp, cfg)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, xp: experiment, cfg: SPLADETRECCast2020Configuration):\n\u001b[0;32m--> 102\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;66;03m# launcher for the index\u001b[39;00m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcpu_launcher_index \u001b[38;5;241m=\u001b[39m find_launcher(cfg\u001b[38;5;241m.\u001b[39mindexation\u001b[38;5;241m.\u001b[39mrequirements)\n",
      "File \u001b[0;32m~/Bureau/M1_DAC_2022_2023/PLDAC/experimaestro-ir/src/xpmir/papers/pipelines/treccast2020.py:71\u001b[0m, in \u001b[0;36mTRECCast2020Experiment.__init__\u001b[0;34m(self, xp, cfg)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Validation/evaluation split\u001b[39;00m\n\u001b[1;32m     70\u001b[0m ds_val, ds_eval \u001b[38;5;241m=\u001b[39m RandomFold\u001b[38;5;241m.\u001b[39mfolds(dataset\u001b[38;5;241m=\u001b[39mdataset, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m, sizes\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m.93\u001b[39m, \u001b[38;5;241m.7\u001b[39m])\n\u001b[0;32m---> 71\u001b[0m \u001b[43mjobmonitor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mds_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Datasets: train, validation and test\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdocuments: AdhocDocuments \u001b[38;5;241m=\u001b[39m prepare_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mirds.trec-cast.v1.documents\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Bureau/M1_DAC_2022_2023/PLDAC/experimaestro-python/src/experimaestro/utils/jobs.py:63\u001b[0m, in \u001b[0;36mjobmonitor\u001b[0;34m(*outputs)\u001b[0m\n\u001b[1;32m     61\u001b[0m                     reporter\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m100\u001b[39m \u001b[38;5;241m-\u001b[39m progress)\n\u001b[1;32m     62\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 63\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     64\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJob did not complete successfully (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     65\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheck the error log \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     66\u001b[0m                 )\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Job did not complete successfully (ERROR).Check the error log /home/gameselo/Bureau/M1_DAC_2022_2023/PLDAC/xp/ri/jobs/xpmir.datasets.adapters.randomfold/19124417b1a856b73072568f25fb3a315218938e07d4b3851527cf6d7dd8eb92/randomfold.err"
     ]
    }
   ],
   "source": [
    "# Run by:\n",
    "# $ xpmir papers splade spladeV2 --configuration config_name index/\n",
    "\n",
    "\n",
    "class SPLADEIndex(SPLADETRECCast2020Experiment):\n",
    "    \"\"\"SPLADEv2 models\"\"\"\n",
    "\n",
    "    cfg: SPLADE_TREC\n",
    "\n",
    "    basemodel = BM25()\n",
    "\n",
    "    def __init__(self, xp: experiment, cfg: SPLADE_TREC):\n",
    "        super().__init__(xp, cfg)\n",
    "        self.gpu_launcher_learner = find_launcher(cfg.learner.requirements)\n",
    "        self.gpu_launcher_evaluate = find_launcher(cfg.evaluation.requirements)\n",
    "        \n",
    "    @lru_cache\n",
    "    def get_optimizers(self, cfg: LearnerConfig):\n",
    "        scheduler = (\n",
    "            LinearWithWarmup(num_warmup_steps=cfg.num_warmup_steps)\n",
    "            if cfg.scheduler\n",
    "            else None\n",
    "        )\n",
    "\n",
    "        return get_optimizers(\n",
    "            [\n",
    "                ParameterOptimizer(\n",
    "                    scheduler=scheduler,\n",
    "                    optimizer=AdamW(lr=cfg.lr),\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"SPLADE model (only indexing)\"\"\"\n",
    "\n",
    "        cfg = self.cfg\n",
    "        # -----Learning to rank component preparation part-----\n",
    "\n",
    "        # Define the model and the flop loss for regularization\n",
    "        # Model of class: DotDense()\n",
    "        # The parameters are the regularization coeff for the query and document\n",
    "        if cfg.learner.model == \"splade_max\":\n",
    "            spladev2, flops = spladeV2_max(\n",
    "                cfg.learner.lambda_q,\n",
    "                cfg.learner.lambda_d,\n",
    "                cfg.learner.lamdba_warmup_steps,\n",
    "            )\n",
    "        elif cfg.learner.model == \"splade_doc\":\n",
    "            spladev2, flops = spladeV2_doc(\n",
    "                cfg.learner.lambda_q,\n",
    "                cfg.learner.lambda_d,\n",
    "                cfg.learner.lamdba_warmup_steps,\n",
    "            )\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        \n",
    "        # define the trainer\n",
    "        batchwise_trainer_flops = BatchwiseTrainer(\n",
    "            batch_size=cfg.learner.splade_batch_size,\n",
    "            sampler=PairwiseSampler,\n",
    "            lossfn=SoftmaxCrossEntropy(),\n",
    "            hooks=[flops],\n",
    "        )\n",
    "\n",
    "        # hooks for the learner\n",
    "        if cfg.learner.model == \"splade_doc\":\n",
    "            hooks = [\n",
    "                setmeta(\n",
    "                    DistributedHook(models=[spladev2.encoder]),\n",
    "                    True,\n",
    "                )\n",
    "            ]\n",
    "        else:\n",
    "            hooks = [\n",
    "                setmeta(\n",
    "                    DistributedHook(models=[spladev2.encoder, spladev2.query_encoder]),\n",
    "                    True,\n",
    "                )\n",
    "            ]\n",
    "\n",
    "        # establish the validation listener\n",
    "        validation = ValidationListener(\n",
    "            id=\"bestval\",\n",
    "            dataset=self.ds_val,\n",
    "            # a retriever which use the splade model to score all the\n",
    "            # documents and then do the retrieve\n",
    "            retriever=spladev2.getRetriever(\n",
    "                self.base_retriever_full,\n",
    "                cfg.full_retriever.batch_size_full_retriever,\n",
    "                PowerAdaptativeBatcher(),\n",
    "                device=self.device,\n",
    "            ),\n",
    "            early_stop=cfg.learner.early_stop,\n",
    "            validation_interval=cfg.learner.validation_interval,\n",
    "            metrics={\"RR@10\": True, \"AP\": False, \"nDCG@10\": False},\n",
    "            store_last_checkpoint=True if cfg.learner.model == \"splade_doc\" else False,\n",
    "        )\n",
    "\n",
    "        # the learner: Put the components together\n",
    "        learner = Learner(\n",
    "            # Misc settings\n",
    "            random=self.random,\n",
    "            device=self.device,\n",
    "            # How to train the model\n",
    "            trainer=batchwise_trainer_flops,\n",
    "            # the model to be trained\n",
    "            scorer=spladev2.tag(\"model\", \"splade-v2\"),\n",
    "            # Optimization settings\n",
    "            optimizers=self.get_optimizers(cfg.learner),\n",
    "            steps_per_epoch=cfg.learner.steps_per_epoch,\n",
    "            use_fp16=True,\n",
    "            max_epochs=tag(cfg.learner.max_epochs),\n",
    "            # the listener for the validation\n",
    "            listeners=[validation],\n",
    "            # the hooks\n",
    "            hooks=hooks,\n",
    "        )\n",
    "\n",
    "        # submit the learner and build the symbolique link\n",
    "        outputs = learner.submit(launcher=self.gpu_launcher_learner)\n",
    "        self.tb.add(learner, learner.logpath)\n",
    "\n",
    "        # get the trained model\n",
    "        trained_model = (\n",
    "            outputs.listeners[\"bestval\"][\"last_checkpoint\"]\n",
    "            if cfg.learner.model == \"splade_doc\"\n",
    "            else outputs.listeners[\"bestval\"][\"RR@10\"]\n",
    "        )\n",
    "\n",
    "        # build a retriever for the documents\n",
    "        sparse_index = SparseRetrieverIndexBuilder(\n",
    "            batch_size=16,\n",
    "            batcher=PowerAdaptativeBatcher(),\n",
    "            encoder=DenseQueryEncoder(scorer=trained_model),\n",
    "            device=self.device,\n",
    "            documents=self.documents,\n",
    "            ordered_index=False,\n",
    "        ).submit(launcher=self.gpu_launcher_index)\n",
    "        \n",
    "        jobmonitor(sparse_index)\n",
    "        \n",
    "        \n",
    "\n",
    "#@paper_command(schema=SPLADE, package=__package__)\n",
    "SPLADEIndex(experiment, SPLADE_TREC).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8f250f-653a-487a-8b69-a7fbb61f9770",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
