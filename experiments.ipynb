{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f59c6c15-1c37-4e79-ad80-d31ebd6f8bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVOIR UTILISER GPU SALLE TP (407 509 502)\n",
    "# entrainer modele generatif avec requete reformulée et requete non reformulée avec splade avec jeu de données de reformulation de requetes (CANARD)\n",
    "# voir encodage et voir re-ranking (pour les améliorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2eb4a84-458d-499d-b809-a18ac8e77908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ir_datasets\n",
    "import ir_measures\n",
    "import logging\n",
    "import os\n",
    "import multiprocessing\n",
    "\n",
    "import pyterrier as pt\n",
    "# pt.init()\n",
    "\n",
    "import pytrec_eval\n",
    "from experimaestro import experiment\n",
    "from datamaestro import prepare_dataset\n",
    "from xpmir.measures import Measure, AP, nDCG, RR, P\n",
    "from xpmir.interfaces.anserini import IndexCollection, AnseriniRetriever\n",
    "from xpmir.rankers.standard import BM25\n",
    "from xpmir.evaluation import Evaluate\n",
    "from transformers import GPT2Tokenizer, GPT2Model, TFGPT2Model, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from xpmir.models import AutoModel\n",
    "from xpmir.neural.colbert import Colbert\n",
    "from xpmir.neural.splade import spladeV2_doc, spladeV2_max\n",
    "\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f1c548-0dcb-4f4b-ba11-d543eb30d5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT2 PYTORCH MODEL\n",
    "\n",
    "tokenizer_gpt2 = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model_gpt2pt = GPT2Model.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f68f370b-46c0-4d66-86ba-5af784ea3bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2Model.\n",
      "\n",
      "All the layers of TFGPT2Model were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2Model for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# GPT2 TENSORFLOW MODEL\n",
    "\n",
    "tokenizer_gpt2 = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model_gpt2tf = TFGPT2Model.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82071a53-9885-4a08-9281-f40c0dd6977e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gameselo/miniconda3/envs/mapsi/lib/python3.9/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# T5 HUGGINGFACE MODEL\n",
    "\n",
    "tokenizer_t5 = AutoTokenizer.from_pretrained(\"t5-base\")\n",
    "\n",
    "model_t5 = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f5f22bf-79dd-44eb-b65a-0e9953274fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MONOT5 RE-RANKER MODEL (MSMARCO FINE-TUNED)\n",
    "\n",
    "tokenizer_monot5 = AutoTokenizer.from_pretrained(\"castorini/monot5-base-msmarco-10k\")\n",
    "\n",
    "model_monot5 = AutoModelForSeq2SeqLM.from_pretrained(\"castorini/monot5-base-msmarco-10k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6389c63d-6ee0-4086-825a-08f2c75d8bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71b1c842c9594b18bf187bb459c2771a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MONOBERT\n",
    "\n",
    "model_monobert = AutoModel.load_from_hf_hub(\"xpmir/monobert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "532ff833-95ec-45ce-aabb-43da6d0b4034",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "dataset_xpmir = prepare_dataset(\"irds.vaswani\")\n",
    "\n",
    "dataset2020 = prepare_dataset(\"irds.trec-cast.v1.2020\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67700efb-1a48-4d47-8a0d-7f70f034e905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASETS FOR TREC 2021\n",
    "dataset2 = prepare_dataset(\"irds.msmarco-document.trec-dl-2020\")\n",
    "dataset3 = ir_datasets.load(\"wapo/v3/trec-news-2020\")\n",
    "dataset4 = prepare_dataset(\"irds.kilt.codec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cca70824-3431-4076-bcc2-761104030f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:xpm:Submitting job Job[a23d25d9fa3cbc0f1047ec4440c40ae0e2eddca3c5b3115ae2807ce359843090]\n",
      "INFO:xpm:Starting job /home/gameselo/Bureau/M1_DAC_2022_2023/PLDAC/experiments/jobs/xpmir.interfaces.anserini.indexcollection/a23d25d9fa3cbc0f1047ec4440c40ae0e2eddca3c5b3115ae2807ce359843090\n",
      "INFO:xpm:Process started (Process(13920))\n",
      "INFO:xpm:Submitting job Job[4a6e21090ad3fd5ff63c29a7898bc7b7f98b9b17647374b6f654f0235a305d05]\n",
      "WARNING:xpm:Signal received\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BM25 results\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/gameselo/Bureau/M1_DAC_2022_2023/PLDAC/experiments/jobs/xpmir.evaluation.evaluate/4a6e21090ad3fd5ff63c29a7898bc7b7f98b9b17647374b6f654f0235a305d05/aggregated.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 15\u001b[0m\n\u001b[1;32m     10\u001b[0m     bm25_eval \u001b[38;5;241m=\u001b[39m Evaluate(dataset\u001b[38;5;241m=\u001b[39mdataset2020, retriever\u001b[38;5;241m=\u001b[39mbm25_retriever, measures\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     11\u001b[0m         AP\u001b[38;5;241m@\u001b[39m\u001b[38;5;241m10\u001b[39m, nDCG\u001b[38;5;241m@\u001b[39m\u001b[38;5;241m3\u001b[39m, RR, nDCG\u001b[38;5;241m@\u001b[39m\u001b[38;5;241m10\u001b[39m, R\u001b[38;5;241m@\u001b[39m\u001b[38;5;241m10\u001b[39m\n\u001b[1;32m     12\u001b[0m     ])\u001b[38;5;241m.\u001b[39msubmit()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBM25 results\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28mprint\u001b[39m(bm25_eval\u001b[38;5;241m.\u001b[39mresults\u001b[38;5;241m.\u001b[39mread_text())\n",
      "File \u001b[0;32m~/miniconda3/envs/mapsi/lib/python3.9/pathlib.py:1266\u001b[0m, in \u001b[0;36mPath.read_text\u001b[0;34m(self, encoding, errors)\u001b[0m\n\u001b[1;32m   1262\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_text\u001b[39m(\u001b[38;5;28mself\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1263\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;124;03m    Open the file in text mode, read it, and close the file.\u001b[39;00m\n\u001b[1;32m   1265\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1266\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m   1267\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m f\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m~/miniconda3/envs/mapsi/lib/python3.9/pathlib.py:1252\u001b[0m, in \u001b[0;36mPath.open\u001b[0;34m(self, mode, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m   1246\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, buffering\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1247\u001b[0m          errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1248\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1249\u001b[0m \u001b[38;5;124;03m    Open the file pointed by this path and return a file object, as\u001b[39;00m\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;124;03m    the built-in open() function does.\u001b[39;00m\n\u001b[1;32m   1251\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mopener\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_opener\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mapsi/lib/python3.9/pathlib.py:1120\u001b[0m, in \u001b[0;36mPath._opener\u001b[0;34m(self, name, flags, mode)\u001b[0m\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_opener\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, flags, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0o666\u001b[39m):\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;66;03m# A stub for the opener argument to built-in open()\u001b[39;00m\n\u001b[0;32m-> 1120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/gameselo/Bureau/M1_DAC_2022_2023/PLDAC/experiments/jobs/xpmir.evaluation.evaluate/4a6e21090ad3fd5ff63c29a7898bc7b7f98b9b17647374b6f654f0235a305d05/aggregated.txt'"
     ]
    }
   ],
   "source": [
    "# EXPERIMENTS\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "with experiment(\"experiments\", \"bm25\", port=12345) as xp:\n",
    "    xp.setenv(\"JAVA_HOME\", os.environ[\"JAVA_HOME\"])\n",
    "    \n",
    "    index = IndexCollection(documents=dataset2020.documents, storePositions=True, storeDocvectors=True, storeContents=True, threads=6).submit()\n",
    "    bm25_retriever = AnseriniRetriever(k=1000, index=index, model=BM25())\n",
    "    bm25_eval = Evaluate(dataset=dataset2020, retriever=bm25_retriever, measures=[\n",
    "        AP@10, nDCG@3, RR, nDCG@10, R@10\n",
    "    ]).submit()\n",
    "\n",
    "print(\"BM25 results\")\n",
    "print(bm25_eval.results.read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e8895b-9f4f-4f46-858a-d4ec087f0ce6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8392c566-752f-4c9c-a681-f6118ff366e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
